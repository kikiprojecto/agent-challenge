# ⚠️ CRITICAL: Choose model based on your system RAM!
# Model Memory Requirements:
# - qwen2.5-coder:1.5b → 1GB RAM (Fastest, basic quality)
# - qwen2.5-coder:3b → 2GB RAM (RECOMMENDED - Best balance) ⭐
# - qwen2.5-coder:7b → 4.3GB RAM (High quality, may fail on 4GB systems)
# - qwen2.5-coder:14b → 8GB RAM (Best quality, requires 8GB+ RAM)

# LOCAL DEVELOPMENT (RECOMMENDED)
# 1. Install Ollama: https://ollama.com/download
# 2. Pull model: ollama pull qwen2.5-coder:3b
# 3. Start Ollama: ollama serve
# 4. Use configuration below:
OLLAMA_API_URL=http://localhost:11434/api
MODEL_NAME_AT_ENDPOINT=qwen2.5-coder:3b

# ALTERNATIVE: Smaller model for systems with <4GB RAM
# OLLAMA_API_URL=http://localhost:11434/api
# MODEL_NAME_AT_ENDPOINT=qwen2.5-coder:1.5b

# ALTERNATIVE: Larger model for systems with 6GB+ RAM
# OLLAMA_API_URL=http://localhost:11434/api
# MODEL_NAME_AT_ENDPOINT=qwen2.5-coder:7b

# REMOTE: Nosana Endpoint (if using remote Ollama)
# OLLAMA_API_URL=https://<nosana-url-id>.node.k8s.prd.nos.ci/api
# MODEL_NAME_AT_ENDPOINT=qwen3:8b

# OpenAI - Uncomment and add apikey to use OpenAI
# Uncomment the corresponding line in `src/mastra/agents/index.ts` to use OpenAI
# OPENAI_API_KEY=
